{
    "nbformat_minor": 0, 
    "metadata": {
        "language_info": {
            "name": "python", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "version": "3.5.2", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 3
            }, 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py"
        }, 
        "kernelspec": {
            "name": "python3-spark20", 
            "display_name": "Python 3.5 (Experimental) with Spark 2.0", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "source": "\nfrom pyspark.sql import SparkSession\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_f0d6ce325e0f4bc08812229b8d429dbe(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '9a0cc60102244d368e96a83f25d4ca89')\n    hconf.set(prefix + '.username', '0caf8026c98a4342ac027a05416e6dee')\n    hconf.set(prefix + '.password', 'D[Cvr1bgf9DM^I{C')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_f0d6ce325e0f4bc08812229b8d429dbe(name)\n\nspark = SparkSession.builder.getOrCreate()\n\n# Since JSON data can be semi-structured and contain additional metadata, it is possible that you might face issues with the DataFrame layout.\n# Please read the documentation of 'SparkSession.read()' to learn more about the possibilities to adjust the data loading.\n# PySpark documentation: http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.json\n\ndf_data_1 = spark.read.json('swift://CursoSpark.' + name + '/funcionarios.json')\n# df_data_1.take(5)\n", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 1, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "funcDF = df_data_1", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 2, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "funcDF.show()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 3, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+------+-----+----------------+-------+----+\n|deptid|idade|            nome|salario|sexo|\n+------+-----+----------------+-------+----+\n|  1000|   42|   Josias Rebelo|   7000|   m|\n|  2000|   50|Mauricio Gonheim|   9500|   m|\n|  1000|   36| Bruno Velasquez|   6700|   m|\n|  1000|   41|  Ananda Tavares|   9300|   f|\n|  2000|   34|     Carlos Maia|   5500|   m|\n+------+-----+----------------+-------+----+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "funcDF.printSchema()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 4, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "root\n |-- deptid: string (nullable = true)\n |-- idade: string (nullable = true)\n |-- nome: string (nullable = true)\n |-- salario: string (nullable = true)\n |-- sexo: string (nullable = true)\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "type(funcDF)", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 5, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "pyspark.sql.dataframe.DataFrame"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 5
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "funcDF.select(\"nome\").show()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 6, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+----------------+\n|            nome|\n+----------------+\n|   Josias Rebelo|\n|Mauricio Gonheim|\n| Bruno Velasquez|\n|  Ananda Tavares|\n|     Carlos Maia|\n+----------------+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "funcDF.filter(funcDF[\"idade\"]==\"50\").show()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 8, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+------+-----+----------------+-------+----+\n|deptid|idade|            nome|salario|sexo|\n+------+-----+----------------+-------+----+\n|  2000|   50|Mauricio Gonheim|   9500|   m|\n+------+-----+----------------+-------+----+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "funcDF.groupBy(\"sexo\").count().show()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 11, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+----+-----+\n|sexo|count|\n+----+-----+\n|   m|    4|\n|   f|    1|\n+----+-----+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "funcDF.groupBy(\"deptid\").agg({\"salario\":\"avg\",\"idade\":\"max\"}).show()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 14, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+------+----------+-----------------+\n|deptid|max(idade)|     avg(salario)|\n+------+----------+-----------------+\n|  2000|        50|           7500.0|\n|  1000|        42|7666.666666666667|\n+------+----------+-----------------+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "# Registrando uma tabela temporaria\nfuncDF.createOrReplaceTempView(\"funcionario\")", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 15, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "spark.sql(\"Select deptid, max(idade),avg(salario) from funcionario group by deptid\").show()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 17, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+------+----------+----------------------------+\n|deptid|max(idade)|avg(CAST(salario AS DOUBLE))|\n+------+----------+----------------------------+\n|  2000|        50|                      7500.0|\n|  1000|        42|           7666.666666666667|\n+------+----------+----------------------------+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "# Registrando o dataframe como temp table\nfuncDF.createOrReplaceTempView(\"funcTB\")", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 18, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "spark.sql(\"select * from funcTB where salario > 6000\").show()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 20, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+------+-----+----------------+-------+----+\n|deptid|idade|            nome|salario|sexo|\n+------+-----+----------------+-------+----+\n|  1000|   42|   Josias Rebelo|   7000|   m|\n|  2000|   50|Mauricio Gonheim|   9500|   m|\n|  1000|   36| Bruno Velasquez|   6700|   m|\n|  1000|   41|  Ananda Tavares|   9300|   f|\n+------+-----+----------------+-------+----+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "#Persistindo a temp table\nfuncTB3 = spark.table(\"funcTB\")", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 21, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "type(funcTB3)", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 22, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "pyspark.sql.dataframe.DataFrame"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 22
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "funcTB3.filter(\"idade='42'\").show()", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 25, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+------+-----+-------------+-------+----+\n|deptid|idade|         nome|salario|sexo|\n+------+-----+-------------+-------+----+\n|  1000|   42|Josias Rebelo|   7000|   m|\n+------+-----+-------------+-------+----+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "outputs": [], 
            "cell_type": "code"
        }
    ]
}