{
    "nbformat_minor": 0, 
    "cells": [
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# <font color='blue'>Data Science Academy Big Data Real-Time Analytics com Python e Spark</font>\n\n# <font color='blue'>Cap\u00edtulo 9</font>"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## <font color='blue'>Spark MLLib - Sistema de Recomenda\u00e7\u00e3o</font>"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "<strong> Descri\u00e7\u00e3o </strong>\n<ul style=\"list-style-type:square\">\n  <li>Tamb\u00e9m chamado de filtros colaborativos.</li>\n  <li>Analisa dados passados para compreender comportamentos de pessoas/entidades.</li>\n  <li>A recomenda\u00e7\u00e3o \u00e9 feita por similaridade de comportamento.</li>\n  <li>Recomenda\u00e7\u00e3o baseada em usu\u00e1rios ou items.</li>\n  <li>Algoritmos de Recomenda\u00e7\u00e3o esperam receber os dados em um formato espec\u00edfico: [user_ID, item_ID, score].</li>\n  <li>Score, tamb\u00e9m chamado rating, indica a prefer\u00eancia de um usu\u00e1rio sobre um item. Podem ser valores booleanos, ratings ou mesmo volume de vendas.</li>\n</ul>"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "from pyspark.ml.recommendation import ALS", 
            "execution_count": 2
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[u'1001,9001,10',\n u'1001,9002,1',\n u'1001,9003,9',\n u'1002,9001,3',\n u'1002,9002,5',\n u'1002,9003,1',\n u'1002,9004,10',\n u'1003,9001,2',\n u'1003,9002,6',\n u'1003,9003,2',\n u'1003,9004,9',\n u'1003,9005,10',\n u'1003,9006,8',\n u'1003,9007,9',\n u'1004,9001,9',\n u'1004,9002,2',\n u'1004,9003,8',\n u'1004,9004,3',\n u'1004,9010,10',\n u'1004,9011,9',\n u'1004,9012,8',\n u'1005,9001,8',\n u'1005,9002,3',\n u'1005,9003,7',\n u'1005,9004,1',\n u'1005,9010,9',\n u'1005,9011,10',\n u'1005,9012,9',\n u'1005,9013,8',\n u'1005,9014,1',\n u'1005,9015,1',\n u'1006,9001,7',\n u'1006,9002,4',\n u'1006,9003,8',\n u'1006,9004,1',\n u'1006,9010,7',\n u'1006,9011,6',\n u'1006,9012,9']"
                    }, 
                    "output_type": "execute_result", 
                    "execution_count": 3, 
                    "metadata": {}
                }
            ], 
            "source": "#Acesso ao Hadoop e leitura do arquivo source\nfrom pyspark.sql import SparkSession\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_f0d6ce325e0f4bc08812229b8d429dbe(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '9a0cc60102244d368e96a83f25d4ca89')\n    hconf.set(prefix + '.username', '0caf8026c98a4342ac027a05416e6dee')\n    hconf.set(prefix + '.password', 'D[Cvr1bgf9DM^I{C')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_f0d6ce325e0f4bc08812229b8d429dbe(name)\n\nspark = SparkSession.builder.getOrCreate()\n\n# Carrega os dados no formato ALS (user, item, rating)\nratingsRDD = sc.textFile('swift://CursoSpark.' + name + '/user-item.csv')\nratingsRDD.collect()", 
            "execution_count": 3
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "# Convertendo as strings\nratingsRDD2 = ratingsRDD.map(lambda l: l.split(',')).map(lambda l:(int(l[0]), int(l[1]), float(l[2])))", 
            "execution_count": 4
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "source": "# Criando um Dataframe\nratingsDF = spark.createDataFrame(ratingsRDD2, [\"user\", \"item\", \"rating\"])", 
            "execution_count": 6
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+----+----+------+\n|user|item|rating|\n+----+----+------+\n|1001|9001|  10.0|\n|1001|9002|   1.0|\n|1001|9003|   9.0|\n|1002|9001|   3.0|\n|1002|9002|   5.0|\n|1002|9003|   1.0|\n|1002|9004|  10.0|\n|1003|9001|   2.0|\n|1003|9002|   6.0|\n|1003|9003|   2.0|\n|1003|9004|   9.0|\n|1003|9005|  10.0|\n|1003|9006|   8.0|\n|1003|9007|   9.0|\n|1004|9001|   9.0|\n|1004|9002|   2.0|\n|1004|9003|   8.0|\n|1004|9004|   3.0|\n|1004|9010|  10.0|\n|1004|9011|   9.0|\n+----+----+------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "ratingsDF.show()", 
            "execution_count": 6
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "source": "# Construindo o modelo\n# ALS = Alternating Least Squares --> Algoritmo para sistema de recomenda\u00e7\u00e3o, que otimiza a loss function \n# e funciona muito bem em ambientes paralelizados\nals = ALS(rank = 10, maxIter = 5)\nmodelo = als.fit(ratingsDF)", 
            "execution_count": 7
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(id=1001, features=[0.3847953975200653, -1.4223843812942505, 0.5573229789733887, -0.08178026974201202, -0.4382185637950897, -0.25812771916389465, -0.2802934944629669, -0.5862515568733215, 0.06860082596540451, -0.49479079246520996]),\n Row(id=1002, features=[0.29569128155708313, 0.9334215521812439, 0.9352413415908813, -0.059310633689165115, -0.26951032876968384, 0.7360463738441467, -0.9229599833488464, 0.36304736137390137, 0.774177074432373, -0.1584303230047226]),\n Row(id=1003, features=[-0.006305389571934938, 1.0576293468475342, 0.7409896850585938, 0.11010909080505371, -0.3228450119495392, 0.5235232710838318, -0.0926164761185646, 0.32665541768074036, 0.9997615814208984, -0.425375372171402]),\n Row(id=1004, features=[0.39390310645103455, -0.6805849671363831, 0.7696443200111389, -0.20997174084186554, -0.5397744178771973, -0.14010731875896454, -0.591958224773407, -0.631860613822937, 0.19471824169158936, -0.5572392344474792]),\n Row(id=1005, features=[0.20535527169704437, -1.1405640840530396, 0.5781751871109009, 0.22730626165866852, -0.3152378499507904, 0.19859527051448822, 0.032358214259147644, 0.22133538126945496, 0.5113064050674438, -0.27636978030204773]),\n Row(id=1006, features=[-0.12187369912862778, -0.3385516405105591, 0.318805068731308, 0.21930280327796936, -0.4121549427509308, -0.3028799295425415, 0.9979380369186401, -0.46029412746429443, 0.7736548781394958, -0.963756263256073])]"
                    }, 
                    "output_type": "execute_result", 
                    "execution_count": 8, 
                    "metadata": {}
                }
            ], 
            "source": "# Visualizando o Affinity Score\nmodelo.userFactors.orderBy(\"id\").collect()", 
            "execution_count": 8
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "source": "# Criando um dataset de teste com usu\u00e1rios e items para rating\ntesteDF = spark.createDataFrame([(1001, 9003),(1001,9004),(1001,9005)], [\"user\", \"item\"])", 
            "execution_count": 9
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(user=1001, item=9004, prediction=-0.6144895553588867),\n Row(user=1001, item=9005, prediction=-3.166208505630493),\n Row(user=1001, item=9003, prediction=8.998315811157227)]"
                    }, 
                    "output_type": "execute_result", 
                    "execution_count": 10, 
                    "metadata": {}
                }
            ], 
            "source": "# Previs\u00f5es  \n# Quanto maior o Affinity Score, maior a probabilidade do usu\u00e1rio aceitar uma recomenda\u00e7\u00e3o\nprevisoes = (modelo.transform(testeDF).collect())\nprevisoes", 
            "execution_count": 10
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# Fim"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "### Obrigado - Data Science Academy - <a href=http://facebook.com/dsacademy>facebook.com/dsacademybr</a>"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "language": "python", 
            "name": "python2-spark20"
        }, 
        "anaconda-cloud": {}, 
        "language_info": {
            "version": "2.7.11", 
            "nbconvert_exporter": "python", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }, 
            "mimetype": "text/x-python", 
            "file_extension": ".py", 
            "name": "python", 
            "pygments_lexer": "ipython2"
        }
    }, 
    "nbformat": 4
}