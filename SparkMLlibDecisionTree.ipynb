{
    "metadata": {
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20"
        }, 
        "language_info": {
            "name": "python", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }, 
            "version": "2.7.11", 
            "mimetype": "text/x-python", 
            "file_extension": ".py", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython2"
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat_minor": 0, 
    "cells": [
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "# <font color='blue'>Data Science Academy Big Data Real-Time Analytics com Python e Spark</font>\n\n# <font color='blue'>Cap\u00edtulo 9</font>"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## <font color='blue'>Spark MLLib - Classifica\u00e7\u00e3o - Decision Tree</font>"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "<strong> Descri\u00e7\u00e3o </strong>\n<ul style=\"list-style-type:square\">\n  <li>F\u00e1cil de compreender e f\u00e1cil de explicar.</li>\n  <li>Vari\u00e1veis preditoras s\u00e3o usadas para construir uma \u00e1rvore que progressivamente prev\u00ea valores target.</li>\n  <li>Dados de treino s\u00e3o usados para construir a \u00e1rvore de decis\u00e3o e prever o valor target.</li>\n  <li>A \u00e1rovre de decis\u00e3o se torna um modelo que \u00e9 usado para fazer previs\u00f5es com novos dados.</li>\n</ul>"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "<dl>\n  <dt>Vantagens</dt>\n  <dd>- F\u00e1cil de interpretar e explicar</dd>\n  <dd>- Funciona com valores missing</dd>\n  <dd>- Veloz</dd>\n  <br />\n  <dt>Desvantagens</dt>\n  <dd>- Acur\u00e1cia limitada</dd>\n  <dd>- Bias podem ocorrer com frequ\u00eancia</dd>\n  <dd>- N\u00e3o funciona bem com muitas vari\u00e1veis preditoras</dd>\n  <br />\n  <dt>Aplica\u00e7\u00e3o</dt>\n  <dd>- Aprova\u00e7\u00e3o de cr\u00e9dito</dd>\n  <dd>- Categoriza\u00e7\u00e3o preliminar</dd>\n</dl>"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Classificar as esp\u00e9cies de flores, listadas no dataset iris"
        }, 
        {
            "execution_count": 1, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "# Credenciais para conex\u00e3o\n# @hidden_cell\ncredentials_1 = {\n  'auth_url':'https://identity.open.softlayer.com',\n  'project':'object_storage_f0d6ce32_5e0f_4bc0_8812_229b8d429dbe',\n  'project_id':'9a0cc60102244d368e96a83f25d4ca89',\n  'region':'dallas',\n  'user_id':'0caf8026c98a4342ac027a05416e6dee',\n  'domain_id':'3be46074545f4c09b1f10df3ace95998',\n  'domain_name':'1351407',\n  'username':'member_327b95c3eecf105b8bdb0125b81968cfcc557dbd',\n  'password':\"\"\"D[Cvr1bgf9DM^I{C\"\"\",\n  'container':'CursoSpark',\n  'tenantId':'undefined',\n  'filename':'iris.csv'\n}\n", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 8, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "\nfrom pyspark.sql import SparkSession\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_f0d6ce325e0f4bc08812229b8d429dbe(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '9a0cc60102244d368e96a83f25d4ca89')\n    hconf.set(prefix + '.username', '0caf8026c98a4342ac027a05416e6dee')\n    hconf.set(prefix + '.password', 'D[Cvr1bgf9DM^I{C')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_f0d6ce325e0f4bc08812229b8d429dbe(name)\n\n# Carregando os dados e gerando um RDD\nfileNameOut = 'swift://'+ credentials_1['container'] + '.keystone/iris.csv' \nirisRDD = sc.textFile(fileNameOut)\n\n", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 9, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 9, 
                    "data": {
                        "text/plain": "pyspark.rdd.RDD"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "type(irisRDD)", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 10, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "from pyspark.sql import Row\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 3, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 11, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 11, 
                    "data": {
                        "text/plain": "swift://CursoSpark.keystone/iris.csv MapPartitionsRDD[4] at textFile at NativeMethodAccessorImpl.java:-2"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "# Colocando o RDD em cache. Esse processo otimiza a performance.\nirisRDD.cache()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 12, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 12, 
                    "data": {
                        "text/plain": "151"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "irisRDD.count()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 13, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 13, 
                    "data": {
                        "text/plain": "[u'Sepal.Length,Sepal.Width,Petal.Length,Petal.Width,Species',\n u'5.1,3.5,1.4,0.2,setosa',\n u'4.9,3,1.4,0.2,setosa',\n u'4.7,3.2,1.3,0.2,setosa',\n u'4.6,3.1,1.5,0.2,setosa']"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "irisRDD.take(5)", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 14, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 14, 
                    "data": {
                        "text/plain": "150"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "# Removendo a primeira linha do arquivo (cabe\u00e7alho)\nirisRDD2 = irisRDD.filter(lambda x: \"Sepal\" not in x)\nirisRDD2.count()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Limpeza dos Dados"
        }, 
        {
            "execution_count": 15, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "# Separando as colunas\nirisRDD3 = irisRDD2.map(lambda l: l.split(\",\"))", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 16, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "# Mapeando as colunas\nirisRDD4 = irisRDD3.map(lambda p: Row(SEPAL_LENGTH = float(p[0]), SEPAL_WIDTH = float(p[1]), \n                                      PETAL_LENGTH = float(p[2]), PETAL_WIDTH = float(p[3]), \n                                      SPECIES = p[4] ))", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 19, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 19, 
                    "data": {
                        "text/plain": "DataFrame[PETAL_LENGTH: double, PETAL_WIDTH: double, SEPAL_LENGTH: double, SEPAL_WIDTH: double, SPECIES: string]"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "# Criando um Dataframe\nirisDF = spark.createDataFrame(irisRDD4)\nirisDF.cache()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 20, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 20, 
                    "data": {
                        "text/plain": "[Row(PETAL_LENGTH=1.4, PETAL_WIDTH=0.2, SEPAL_LENGTH=5.1, SEPAL_WIDTH=3.5, SPECIES=u'setosa'),\n Row(PETAL_LENGTH=1.4, PETAL_WIDTH=0.2, SEPAL_LENGTH=4.9, SEPAL_WIDTH=3.0, SPECIES=u'setosa'),\n Row(PETAL_LENGTH=1.3, PETAL_WIDTH=0.2, SEPAL_LENGTH=4.7, SEPAL_WIDTH=3.2, SPECIES=u'setosa'),\n Row(PETAL_LENGTH=1.5, PETAL_WIDTH=0.2, SEPAL_LENGTH=4.6, SEPAL_WIDTH=3.1, SPECIES=u'setosa'),\n Row(PETAL_LENGTH=1.4, PETAL_WIDTH=0.2, SEPAL_LENGTH=5.0, SEPAL_WIDTH=3.6, SPECIES=u'setosa')]"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "irisDF.take(5)", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 21, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "# Criando um \u00edndice num\u00e9rico para a coluna de label target\nstringIndexer = StringIndexer(inputCol = \"SPECIES\", outputCol = \"IDX_SPECIES\")\nsi_model = stringIndexer.fit(irisDF)\nirisNormDF = si_model.transform(irisDF)", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 22, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 22, 
                    "data": {
                        "text/plain": "[Row(SPECIES=u'versicolor', IDX_SPECIES=0.0),\n Row(SPECIES=u'setosa', IDX_SPECIES=2.0),\n Row(SPECIES=u'virginica', IDX_SPECIES=1.0)]"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "irisNormDF.select(\"SPECIES\",\"IDX_SPECIES\").distinct().collect()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## An\u00e1lise Explorat\u00f3ria de Dados"
        }, 
        {
            "execution_count": 23, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-------+------------------+------------------+------------------+------------------+------------------+\n|summary|      PETAL_LENGTH|       PETAL_WIDTH|      SEPAL_LENGTH|       SEPAL_WIDTH|       IDX_SPECIES|\n+-------+------------------+------------------+------------------+------------------+------------------+\n|  count|               150|               150|               150|               150|               150|\n|   mean| 3.758000000000001|1.1993333333333331| 5.843333333333332|3.0573333333333337|               1.0|\n| stddev|1.7652982332594662|0.7622376689603467|0.8280661279778634|0.4358662849366978|0.8192319205190404|\n|    min|               1.0|               0.1|               4.3|               2.0|               0.0|\n|    max|               6.9|               2.5|               7.9|               4.4|               2.0|\n+-------+------------------+------------------+------------------+------------------+------------------+\n\n"
                }
            ], 
            "cell_type": "code", 
            "source": "# Estat\u00edstica descritiva\nirisNormDF.describe().show()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 24, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "('Correla\\xc3\\xa7\\xc3\\xa3o da vari\\xc3\\xa1vel Species com', 'PETAL_LENGTH', -0.649241830764174)\n('Correla\\xc3\\xa7\\xc3\\xa3o da vari\\xc3\\xa1vel Species com', 'PETAL_WIDTH', -0.5803770334306263)\n('Correla\\xc3\\xa7\\xc3\\xa3o da vari\\xc3\\xa1vel Species com', 'SEPAL_LENGTH', -0.46003915650023686)\n('Correla\\xc3\\xa7\\xc3\\xa3o da vari\\xc3\\xa1vel Species com', 'SEPAL_WIDTH', 0.6183715308237433)\n"
                }, 
                {
                    "output_type": "error", 
                    "ename": "IllegalArgumentException", 
                    "evalue": "u'requirement failed: Currently correlation calculation for columns with dataType StringType not supported.'", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mIllegalArgumentException\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-24-e5177076d0db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mirisNormDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mirisNormDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"Correla\u00e7\u00e3o da vari\u00e1vel Species com\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mirisNormDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'IDX_SPECIES'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[1;32m/usr/local/src/spark20master/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(self, col1, col2, method)\u001b[0m\n\u001b[0;32m   1509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[0mcorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/spark20master/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(self, col1, col2, method)\u001b[0m\n\u001b[0;32m   1291\u001b[0m             raise ValueError(\"Currently only the calculation of the Pearson Correlation \" +\n\u001b[0;32m   1292\u001b[0m                              \"coefficient is supported.\")\n\u001b[1;32m-> 1293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/spark20master/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/usr/local/src/spark20master/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mIllegalArgumentException\u001b[0m: u'requirement failed: Currently correlation calculation for columns with dataType StringType not supported.'"
                    ]
                }
            ], 
            "cell_type": "code", 
            "source": "# Correla\u00e7\u00e3o entre as vari\u00e1veis\nfor i in irisNormDF.columns:\n    if not( isinstance(irisNormDF.select(i).take(1)[0][0], str)) :\n        print( \"Correla\u00e7\u00e3o da vari\u00e1vel Species com\", i, irisNormDF.stat.corr('IDX_SPECIES', i))", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Pr\u00e9-Processamento dos Dados"
        }, 
        {
            "execution_count": 25, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "# Criando um LabeledPoint (target, Vector[features])\n# Remove colunas n\u00e3o relevantes para o modelo ou com baixa correla\u00e7\u00e3o\ndef transformaVar(row) :\n    obj = (row[\"SPECIES\"], row[\"IDX_SPECIES\"], Vectors.dense([row[\"SEPAL_LENGTH\"], row[\"SEPAL_WIDTH\"], \n                                                              row[\"PETAL_LENGTH\"], row[\"PETAL_WIDTH\"]]))\n    return obj", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 26, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "irisRDD5 = irisNormDF.rdd.map(transformaVar)", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 27, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 27, 
                    "data": {
                        "text/plain": "[(u'setosa', 2.0, DenseVector([5.1, 3.5, 1.4, 0.2])),\n (u'setosa', 2.0, DenseVector([4.9, 3.0, 1.4, 0.2])),\n (u'setosa', 2.0, DenseVector([4.7, 3.2, 1.3, 0.2])),\n (u'setosa', 2.0, DenseVector([4.6, 3.1, 1.5, 0.2])),\n (u'setosa', 2.0, DenseVector([5.0, 3.6, 1.4, 0.2]))]"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "irisRDD5.take(5)", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 29, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-------+-----+-----------------+\n|species|label|         features|\n+-------+-----+-----------------+\n| setosa|  2.0|[5.1,3.5,1.4,0.2]|\n| setosa|  2.0|[4.9,3.0,1.4,0.2]|\n| setosa|  2.0|[4.7,3.2,1.3,0.2]|\n| setosa|  2.0|[4.6,3.1,1.5,0.2]|\n| setosa|  2.0|[5.0,3.6,1.4,0.2]|\n| setosa|  2.0|[5.4,3.9,1.7,0.4]|\n| setosa|  2.0|[4.6,3.4,1.4,0.3]|\n| setosa|  2.0|[5.0,3.4,1.5,0.2]|\n| setosa|  2.0|[4.4,2.9,1.4,0.2]|\n| setosa|  2.0|[4.9,3.1,1.5,0.1]|\n+-------+-----+-----------------+\nonly showing top 10 rows\n\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "execution_count": 29, 
                    "data": {
                        "text/plain": "DataFrame[species: string, label: double, features: vector]"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "irisDF = spark.createDataFrame(irisRDD5,[\"species\", \"label\", \"features\"])\nirisDF.select(\"species\",\"label\",\"features\").show(10)\nirisDF.cache()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Machine Learning"
        }, 
        {
            "execution_count": 30, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "# Dados de Treino e de Teste\n(dados_treino, dados_teste) = irisDF.randomSplit([0.7, 0.3])", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 31, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 31, 
                    "data": {
                        "text/plain": "106"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "dados_treino.count()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 32, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 32, 
                    "data": {
                        "text/plain": "44"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "dados_teste.count()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 33, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "# Construindo o modelo com os dados de treino\ndtClassifer = DecisionTreeClassifier(maxDepth = 2, labelCol = \"label\", featuresCol = \"features\")\nmodelo = dtClassifer.fit(dados_treino)", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 34, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 34, 
                    "data": {
                        "text/plain": "2"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "modelo.numNodes\nmodelo.depth", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 35, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 35, 
                    "data": {
                        "text/plain": "[Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=2.0, species=u'setosa', label=2.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=0.0, species=u'versicolor', label=0.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=0.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0),\n Row(prediction=1.0, species=u'virginica', label=1.0)]"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "# Previs\u00f5es com dados de teste\nprevisoes = modelo.transform(dados_teste)\nprevisoes.select(\"prediction\",\"species\",\"label\").collect()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 36, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 36, 
                    "data": {
                        "text/plain": "0.9772727272727273"
                    }, 
                    "metadata": {}
                }
            ], 
            "cell_type": "code", 
            "source": "# Avaliando a acur\u00e1cia\navaliador = MulticlassClassificationEvaluator(predictionCol = \"prediction\", labelCol = \"label\", metricName = \"accuracy\")\navaliador.evaluate(previsoes)      ", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "execution_count": 37, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-----+----------+-----+\n|label|prediction|count|\n+-----+----------+-----+\n|  1.0|       1.0|   18|\n|  2.0|       2.0|    9|\n|  1.0|       0.0|    1|\n|  0.0|       0.0|   16|\n+-----+----------+-----+\n\n"
                }
            ], 
            "cell_type": "code", 
            "source": "# Resumindo as previs\u00f5es - Confusion Matrix\nprevisoes.groupBy(\"label\",\"prediction\").count().show()", 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "# Fim"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Obrigado - Data Science Academy - <a href=http://facebook.com/dsacademy>facebook.com/dsacademybr</a>"
        }
    ], 
    "nbformat": 4
}